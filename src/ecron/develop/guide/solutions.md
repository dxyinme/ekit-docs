# 行业方案

如果你对我们是从什么方面调研的，可以参考这个：
- [2022.12.15 会议纪要](https://github.com/gotomicro/ecron/discussions/1)

## ElasticJob 

ElasticJob 调研由[@yzicheng](https://github.com/yzicheng)完成，[原文](https://gitee.com/yzcgitte/elasticjob/blob/master/ElasticJob.md)

### ElasticJob-Lite

Elastic-Job-Lite 是去中心化的，以 Jar 包提供的轻量级分布式任务协调服务。这种形态有很多好处：
- 用户不需要额外部署服务器，对于中小企业，或者小规模应用来说，是一个极大的成本优势
- 应用本身就可以作为任务调度、任务执行的实例，也是节省成本
- 从开发的角度来说，用户注册一个任务，就和写一个普通的接口差不多

我们可以考虑借鉴这一种思路。也就是说整个任务调度集群，就是应用集群，不再需要额外的集群。又或者说，用户可以自己选择是否采用独立的 ecron 集群，也可以混用。所谓混用就是一些实例就是只部署了 ecron，而另外一些实例就是任务本身和 ecron 的代理部署在一起。

进一步说，这种形态可以衍生为，在用户的应用实例里面部署一个 sidecar，或者将任务调度本身嵌进去一个已有的 sidecar 里面。

![ecron 去中心化思路](img/ecron_no_center.png)

如图所示，其中 ecron 节点，混合节点和混合-sidecar 节点将会参与任务调度，或者主从选举和任务分片之类的事情。

但是任务执行，或者任务本身，ecron 节点就不能参与了，因为它是纯粹的 ecron 节点，上面没有任何的任务逻辑。

更加巧妙地是，我们可以通过加入一个中心节点，比如说 etcd 之类的，来转化成主从结构。那么主节点就只负责分片，从节点负责调度。这种形态就接近 ElasticJob 本身的形态了。可以考虑给予不同的权重来控制调度的负载。例如说对于纯粹的 ecron 节点，权重很高，混合节点权重比较低——应用越是复杂的，权重越低。

### Zookeeper
目前来说，ElasticJob 非常依赖于 Zookeeper。

### 需要确定的点
- Elastic-Job-Lite 是怎么选举的，以及 Elastic-Job-Lite 是怎么发现节点的，用户要配置好，还是通过广播来查找？
- Mesos - Framework 的主要功能、架构设计和核心接口设计
- ElasticJob 和 zookeeper 打交道，是直接操作 zookeeper 还是说抽象出来了一层接口。例如说，如果抽取出来了接口，那么我能不能提供其它实现，比如说基于 etcd 的实现？


## Kubernetes

k8s 的调研部分由 @henrysworld 完成。

### 分析

k8s 整体设计自然是十分优秀的，其中值得我们重点关注和学习的点：
- 声明式设计
- Job 和 CronJob 的分离

#### 声明式设计

这算是 k8s 一贯以来的设计风格。在我们架构设计里面也是打算借鉴这这种设计思路。即所有的任务都会有一份任务规格说明，而所谓的调度引擎就是根据这份规格说明来执行调度。所以总体上来说，我们的设计可以称为配置驱动，或者 spec driven。

#### Job 和 CronJob 分离
理论上来说，在 k8s 里面的 Job 概念，应该只能算是 CronJob 的一种特殊形态。

我们可以设想，假如说我们有一个定时任务是每天 00:30:00 执行一次。那么所谓的一次性任务就是只执行一次的定时任务；而实时任务则是只执行一次的，恰好立刻执行的定时任务。

所以从设计上来说，Job 和 CronJob 的区分是无所谓的，完全可以将它们纳入统一抽象之下。而两个参数 completions 和 parallelism CronJob 一样可以使用。completions 也就是我们调度策略里面谈及的应该在多少个实例上调度，而 parallelism 则可以理解为该任务允许并行调度多少个实例。

> 猜想是因为 k8s 本身不是一个纯粹的任务调度框架，所以受制于其他诸如容器编排的功能，而不得不引入这种区分

#### 任务信息存储

令人惊讶的是，k8s 的所有配置，不管是 Job 还是 CronJob，都是利用 etcd 来存储的。我们可以考虑将 etcd 作为存储引擎的一种实现。因此 k8s 如何在 etcd 上组织自己的 Job 和 CronJob 的配置，就很值得关注。

### 待确认的点
- k8s 的队列是如何设计的：
  - k8s 什么情况下会往里面加入任务？例如说，我有一个每日 00:30:00 执行的任务，这个任务是每天（例如 00:15:00）加入一次，然后执行完，还是使用了什么其它策略？比如说，每天执行一次这一类的任务，k8s 总不可能一次性生成从 2023 年到 2123 年的所有调度信息
  - 在删除或者修改任务的情况下，k8s 怎么快速定位到队列中相关的任务？注意 k8s 是采用遍历，还是接近 map 之类的数据结构 
  - 队列的容量，即它最多允许放置多少个任务？
  - 队列是否有分组之类的机制？例如说，近一分钟内就要被调度的任务在一个组里面；近半小时的在另外一个组里。又或者说整个 k8s 集群只有一个队列，还是说逻辑上只有一个队列，但是内部有很多子队列？
- k8s 的时间精度问题。例如说我们预期在 00:30:00 执行，那么它可能在什么精度的时间范围内调度到这个任务？例如说秒级精度就是会在 00:29:59 - 00:30:01 这个时间段内调度到
- k8s 的任务编排能否解决前置任务这种场景？
- k8s 的容错机制：
  - 任务运行时间过长会如何？
  - 任务失败了，怎么重试？重试一直失败会如何？
  - 如果一个任务占据了很多资源，会不会影响别的任务调度？
  - 如果一个任务是半小时运行一次，但是某一次运行超过了半小时，会造成时间窗口重叠吗？即这个时候会同时有两个同样的任务运行吗？又或者说，当我们说半个小时运行一次的时候，半小时是从上一次任务结束之后开始计时，还是从上一次任务开始运行的时候就开始计时？
- k8s 队列相关的 API（只需要接口）：从队列中增删改查任务的接口，重中之重是调度器怎么从队列里面拿到任务
- Job 和 CronJob 的完整配置：即所有允许用户配置的配置项，以及它们的含义。



## Airflow
Airflow 调研由 @YogiLiu 完成。

### 分析

#### DAG
Airflow 也是使用 DAG（有向无环图）来描述任务之间的依赖。例如：

![Airflow 任务依赖](img/airflow_dag.png)


#### Scheduler 和 Executor

在 Airflow 里面，Scheduler 用于调度任务执行，Executor 是 Airflow 内部代表执行的结构体。真正执行任务的实际上是 Worker，可以认为 Executor 是 Worker 在系统内部的代表。

### 待确认的点
- Airflow 是如何描述 DAG 的。或者说用户该怎么配置，以及 Airflow 是否存在
- Airflow 是如何判断某个任务的前置任务全部已经完成了，也就是可以调度该任务了
- Scheduler 的轮询机制：
  - 要注意，这种轮询机制在任务量非常大的情况下，是否会出现问题
- meta database 表结构设计